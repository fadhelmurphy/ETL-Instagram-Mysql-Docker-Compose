version: '3.9'

services:
  scraper:
    build: 
      context: .
      dockerfile: Dockerfile
    environment:
      - INSTAGRAM_USERNAME=your_instagram_username
      - INSTAGRAM_PASSWORD=your_instagram_password
      - TARGET_POST_URL=CuHZQo8h9RT  # Ganti dengan id postingan yang ingin di-scrape
      - MYSQL_USER=padel_user
      - MYSQL_PASSWORD=padel_password
      - MYSQL_HOST=db
      - MYSQL_DB=padel_db
    depends_on:
      - db

  db:
    image: mysql:latest
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: padel_db
      MYSQL_USER: padel_user
      MYSQL_PASSWORD: padel_password

  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    ports:
      - "8080:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: root
      PMA_ABSOLUTE_URI: http://nginx/mysql-ui  # Ubah absolute URI ke prefix yang baru
    depends_on:
      - db

  nginx:
    image: nginx:latest
    ports:
      - "80:80"  # Ganti port sesuai kebutuhan Anda
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - phpmyadmin
  
  airflow-webserver:
    image: apache/airflow:latest
    # restart: always
    command: >
      bash -c "airflow webserver"
    environment:
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin  # Ganti dengan username yang diinginkan
      - _AIRFLOW_WWW_USER_PASSWORD=admin  # Ganti dengan password yang diinginkan
      - LOAD_EX=n
      - EXECUTOR=Local
    ports:
      - "8081:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    depends_on:
      - db
      - scraper